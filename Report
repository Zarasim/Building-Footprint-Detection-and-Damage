Assessing the extent of damage caused by natural disasters or other events is crucial for emergency response and recovery efforts. Traditional methods for damage assessment rely on manually analyzing aerial images, which can be time-consuming and prone to human error. Deep learning-based object detection techniques offer a promising alternative, enabling automated damage assessment with improved accuracy and efficiency.

YOLO as the Object Detection Model

YOLO (You Only Look Once) is a state-of-the-art object detection algorithm that has gained popularity due to its real-time performance and high accuracy. YOLO's architecture utilizes a convolutional neural network (CNN) to extract features from an image and then predicts bounding boxes around objects along with their corresponding class labels.

Dataset Preparation

For YOLO to effectively detect damaged buildings, it requires a comprehensive training dataset consisting of aerial images with labeled bounding boxes indicating damaged buildings. The dataset should be carefully curated to represent the diversity of building types, damage levels, and environmental conditions.

Data Preprocessing and Augmentation

Preprocessing the raw aerial images involves normalizing pixel values, resizing images to a standard size, and converting color spaces to a format compatible with YOLO. Data augmentation techniques, such as random cropping, flipping, and brightness adjustments, artificially increase the dataset size and improve the model's generalization ability.

Annotation Using Roboflow

Roboflow is a cloud-based platform that simplifies the process of annotating images for object detection tasks. It allows to draw bounding boxes around damaged buildings and planes in aerial images.
The annotation task and the creation of the entire file directories for training, validation and test set is also automatized.

5 labels have been created for the task: [full_damage', 'high_damage', 'low_damage', 'medium_damage', 'plane'].

The dataset has been split into training, validation and test set. The processed data is only present in the test set, while the augmented data is used for training and validation.

NOTE: The dataset contained few images and even data augmentation techniques risk to overfit the model on the training dataset. It is important for real-case scenario to provide a bigger dataset of images and 
also, in the same image, picture buildings in different damaged condition. This will allow the model to accurately classify the status of a highly damaged building even if it is sorrounded by low-level damaged buildings.


Training the YOLO Model

With the prepared dataset, the YOLO model is trained using the PyTorch deep learning framework. The training process involves optimizing the model's parameters to minimize the error between its predictions and the ground truth labels. The output is available at "runs/detect/train". The picture "results.png" shows that over the 30 epochs the training box and class loss keeps decreasing, while the validation loss stagnates after about 20 epochs. It is worth noticing that the precision and recall also stabilizes to the highest values after 20 epochs. The confusion matrix in "confusion_matrix_normalized.png" evidences that only the "plane" category is detected correctly with optimal accuracy, while only about 30% of the low and high damaged buildings have been detected. Remaining percentage is labelled as background labelling.      
With more images, a higher ratio validation/training data, and a bigger YOLO model it would be possible to increase the metrics and obtain better accuracy for the damaged buildings.

Model Evaluation and Deployment

After training, the YOLO model is evaluated on a separate validation dataset to assess its generalization performance. Once the model demonstrates satisfactory accuracy, it can be deployed for real-world applications, such as automated damage assessment in post-disaster scenarios.

Conclusion

YOLO, coupled with proper dataset preparation and annotation, offers a powerful solution for detecting damaged buildings from aerial images. This approach can significantly improve the efficiency and accuracy of damage assessment, providing valuable insights for disaster response and recovery efforts.
